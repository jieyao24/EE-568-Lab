{"cells":[{"cell_type":"markdown","metadata":{"id":"AYERJpbVn-5x"},"source":["## Problem 1: Image Classification by CNN"]},{"cell_type":"markdown","metadata":{"id":"Fj3L0DrOM88X"},"source":["CIFAR-10 dataset has the classes (listed below): ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size $3 \\times 32 \\times 32$, i.e. 3-channel color images of $32 \\times 32$ pixels in size.\n","\n","CIFAR-10 is included in **torchvision**, so we don't have to upload the dataset to Colab.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mqnizXadNh8b"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse',\n","           'ship', 'truck')\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0))])\n","\n","# Randomly split the training set into 45000 training and 5000 validation\n","generator1 = torch.Generator().manual_seed(42)\n","cifar10_trainset, cifar10_valset = torch.utils.data.random_split(datasets.CIFAR10(root='./data/', train=True, download=True, transform=transform), [45000, 5000], generator1)\n","cifar10_testset = datasets.CIFAR10(root='./data/', train=False, download=True, transform=transform)\n","\n","cifar_val_loader = DataLoader(cifar10_valset, batch_size=128, shuffle=False)\n","cifar_test_loader = DataLoader(cifar10_testset, batch_size=128, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"t6CzcJuz7kUx"},"source":["Visualize some samples in the CIFAR-10 dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"igESHithODja"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib import cm\n","\n","def cifar_imshow(img):\n","  img = img + 0.5     # unnormalize\n","  npimg = img.numpy()\n","  return np.transpose(npimg, (1, 2, 0))\n","\n","# TODO: visualize some samples in the CIFAR-10 dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gYnIKkDQ7kUx"},"outputs":[],"source":["cifar_train_loader = DataLoader(cifar10_trainset, batch_size=128, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"dla9pbqz7kUx"},"source":["Given the following network parameters, implement CNN1 using PyTorch.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtUjXNeE7kUx"},"outputs":[],"source":["'''\n","CNN1(\n","  (convs): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(8, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): Conv2d(8, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU(inplace=True)\n","    (9): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (14): ReLU(inplace=True)\n","    (15): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (16): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (17): ReLU(inplace=True)\n","    (18): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (fcs): Sequential(\n","    (0): Linear(in_features=32, out_features=10, bias=True)\n","  )\n",")\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5t2D7wTc7kUy"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CNN1(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    # TODO: define your CNN\n","\n","  def forward(self, x):\n","    # TODO: define your forward function\n","    return outs"]},{"cell_type":"markdown","metadata":{"id":"w5OT4JOo7kUy"},"source":["Let's do classification on CIFAR-10 dataset.\n","**Note**: remember to keep the logs of training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Pe5TZTF7kUy"},"outputs":[],"source":["# use GPU to train if possible\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OSnVpWOr7kUy"},"outputs":[],"source":["n_epoch = 10\n","cnn1 = CNN1().to(device)  # operate on GPU\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(cnn1.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n","for i in range(n_epoch):\n","  # todo: use your train() to train your cnn1 and test() to evaluate on your validation set\n"]},{"cell_type":"markdown","metadata":{"id":"pK1XZPPL7kUy"},"source":["Evaluate the classfication performance on the testing set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-rZZIAY7kUy"},"outputs":[],"source":["# todo: use your test() to test your cnn1"]},{"cell_type":"markdown","metadata":{"id":"Qc4DHtXvjocy"},"source":["#### Data Augmentation"]},{"cell_type":"markdown","metadata":{"id":"IQU6IaAe7kUy"},"source":["In order to mitigate overfitting and simulate real-world data variability, we can transform our data by data augmentation. Here, we will implement some common tricks for data augmentation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IhG9dwnLjs-J"},"outputs":[],"source":["from torch.utils.data import ConcatDataset\n","import copy\n","\n","transform1 = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0))])\n","\n","# TODO: Implements transforms\n","\n","# Shifting: randomly shift the images up/down and left/right by within 10%.\n","transform2 =\n","\n","# Rotating: randomly rotate the images by range (-30 degrees, 30 degrees).\n","transform3 =\n","\n","# Flipping: horizontally flip the images.\n","transform4 =\n","\n","# Adding Noise: randomly add some small Gaussian noise to the images.\n","transform5 =\n","\n","transform_list = [transform1, transform2, transform3, transform4, transform5]\n","augmented_dataset = []\n","for t in transform_list:\n","  dataset = copy.deepcopy(cifar10_trainset)\n","  dataset.transform = t\n","  augmented_dataset.append(dataset)\n","\n","cifar_train_dataset = ConcatDataset(augmented_dataset)\n","cifar_train_loader = DataLoader(cifar_train_dataset, batch_size=128, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"oeOA4vRbV3Pq"},"source":["Use the same CNN architecture to train on the augmented training dataset.\n","\n","**Note**: remember to keep the logs of training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yLIOsIkq7kUy"},"outputs":[],"source":["# use GPU to train if possible\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"hfi4oC0bhHxg"},"source":["Define a loss function and optimizer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lIikPKNI7Ep2"},"outputs":[],"source":["import torch.optim as optim\n","\n","# TODO: you can change loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(cnn1.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)"]},{"cell_type":"markdown","metadata":{"id":"bzvExFSVhL3x"},"source":["Train the network. Evaluate your model at the end of your epoch."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sx7o890o7kUy"},"outputs":[],"source":["n_epoch = 20"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWjbkl5o7Ep5"},"outputs":[],"source":["for i in range(n_epoch):\n","  # todo: use your train() to train your cnn1 and test() to evaluate on your validation set"]},{"cell_type":"markdown","metadata":{"id":"-RGeRQxR7EqG"},"source":["Evaluate the classfication performance on the testing set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9IERp19p7EqH"},"outputs":[],"source":["# todo: use your test() to test your cnn1"]},{"cell_type":"markdown","metadata":{"id":"CFCCqT5LAJ29"},"source":["Define CNN2. Modify CNN1 model by doubling the number of output channels in each layer, for example, changing 8 to 16.\n","Train it on the augmented dataset and report the accuracy on the testing set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"azVlrX7LFQMy"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CNN2(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    # TODO: define your CNN\n","\n","\n","  def forward(self, x):\n","    # TODO: define your forward function\n","\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jlGY3sagFT0s"},"outputs":[],"source":["n_epoch = 20\n","cnn2 = CNN2().to(device)  # operate on GPU\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(cnn2.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n","for i in range(n_epoch):\n","  # todo: use your train() to train your cnn2 and test() to evaluate on your validation set"]},{"cell_type":"markdown","metadata":{"id":"vMszp8bd7kUz"},"source":["Modify the above CNN model by using kernel size of 3 for every convolutional layer.\n","Train it on the augmented dataset and report the accuracy on the testing set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LrO4hB5X7kUz"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CNN3(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    # TODO: define your CNN\n","\n","  def forward(self, x):\n","    # TODO: define your forward function\n","\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_RUcG0Y_GK5"},"outputs":[],"source":["n_epoch = 20\n","cnn3 = CNN3().to(device)  # operate on GPU\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(cnn3.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n","for i in range(n_epoch):\n","  # todo: use your train() to train your cnn3 and test() to evaluate on your validation set"]},{"cell_type":"markdown","metadata":{"id":"wWaCADRZ7kUz"},"source":["Try different optimizers or initial learning rates. Train it on the augmented dataset and report the accuracy on the testing set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7EgTG-oy7kUz"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"gsOEhNpuzhlg"},"source":["####  Discussion"]},{"cell_type":"markdown","metadata":{"id":"frupe8HZ1ylk"},"source":["Based on your experiments in Problem 1, what can potentially affect your performance most?\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
