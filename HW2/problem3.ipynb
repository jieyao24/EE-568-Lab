{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na2O0VwH4nsO"
      },
      "source": [
        "# Problem 3: Transfer Learning and Domain Adaptation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjCV8OFc6awr"
      },
      "source": [
        "The goal of domain adaptation is to transfer the knowledge of a model to a different but related data distribution. The model is trained on a source dataset and applied to a target dataset (usually unlabeled). For Problem 3, the model will be trained on regular MNIST images, but we want to get good performance on MNIST with random color (without any labels).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfinfRb16fT_"
      },
      "source": [
        "**Problem Statement** Given a labelled source domain (MNIST) and an unlabelled target domain (MNIST-M). We would like to train a classifier or a predictor which would give accurate predictions on the target domain. \n",
        "\n",
        "**Assumptions** Probability distribution of source domain is not equal to the probability distribution of target domain. The conditional probability distribution of the labels given an instance from the source domain is equal to the conditional probability distribution of the labels given an instance from the target domain. Source dataset is labelled. Target dataset is unlabelled.\n",
        "\n",
        "**Approach** Here, we adopt the DABP method mentioned in the paper “Unsupervised Domain Adaptation by Backpropagation”.\n",
        "\n",
        "* Feature Extractor (green): This is a neural network that will learn to perform the transformation on the source and target distribution. \n",
        "* Label Classifier (blue): This is a neural network that will learn to perform the classification on the transformed source distribution. Since, the source domain is labelled. \n",
        "* Domain Classifier (red): This is a neural network that will predict whether the output of the Feature Extractor is from the source distribution or the target distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YpTheb-6u87"
      },
      "source": [
        "By using the above three components, the Feature Extractor will learn to produce discriminative and domain-invariant features. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki1QDNkZ7AKN"
      },
      "outputs": [],
      "source": [
        "# download the codes from Git\n",
        "!git clone https://github.com/Haotian-Zhang/Pytorch_DABP.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUHlfPzg7W36"
      },
      "source": [
        "Train the DABP model by running `main.py` and answer the following questions. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4ypSoWm7Z2b"
      },
      "source": [
        "* Q1: Perform **3** experiments on training and report your source and target accuracy in the tables below. (Your result is the average of the Target Accs. based on 3 experiments)\n",
        "\n",
        "**Source Only**\n",
        "\n",
        "|                | Test1 | Test2 | Test3 |\n",
        "|----------------|:-----:|:-----:|:-----:|\n",
        "| Source Acc (%) |    |       |       |\n",
        "| Target Acc (%) |    |       |      |\n",
        "\n",
        "|          | Paper | Your Result |\n",
        "|----------|:-----:|:-----------:|\n",
        "| DABP (%) | 52.25 |          |\n",
        "\n",
        "**DANN**\n",
        "\n",
        "|                | Test1 | Test2 | Test3 |\n",
        "|----------------|:-----:|:-----:|:-----:|\n",
        "| Source Acc (%) |    |       |        |\n",
        "| Target Acc (%) |   |       |       |\n",
        "\n",
        "|          | Paper | Your Result |\n",
        "|----------|:-----:|:-----------:|\n",
        "| DABP (%) | 76.66 |          |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbdz6ZHyckKP"
      },
      "outputs": [],
      "source": [
        "!python Pytorch_DABP/main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLFcP0xO876a"
      },
      "source": [
        "* Q2: Write your own codes to visualize the feature space by using the TSNE(perplexity=30, n_components=2, init=’pca’, n_iter=3000). Plot the feature distributions for both (1) original MNIST and MNIST-M inputs and (2) after DABP using source only (3) after DABP using dann.(**You will find useful functions inside the `utils`function.** )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCL18DHg2Mde"
      },
      "source": [
        "(1) Original MNIST and MNIST-M inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTt-JFPK81ig"
      },
      "outputs": [],
      "source": [
        "# todo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwHXZv8gp1W-"
      },
      "source": [
        "(2) After DABP using source only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37NlBMhvrWRz"
      },
      "outputs": [],
      "source": [
        "# todo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCy4cnx52WO0"
      },
      "source": [
        " (3) After DABP using dann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUqmY9_o2aEF"
      },
      "outputs": [],
      "source": [
        "# todo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWsmdkcSDLSe"
      },
      "source": [
        "## Discussions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe4x56cF2lXf"
      },
      "source": [
        "(1) From the results in Q2, are the both domains closer/farther after performing the transformation? If the answer is closer, it verifies that DABP can learn discriminative and domain invariant features. If not, explain your reasons.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLt_K7AW5puN"
      },
      "source": [
        "(2) List one of the main problems for the DABP method and explain why?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
