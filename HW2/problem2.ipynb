{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qHZTpff7FaoX"
      },
      "source": [
        "# Problem 2: Long-Tailed Recognition on Imbalanced Dataset\n",
        "\n",
        "In the existing visual recognition setting, the training data and testing data are both balanced under a closed-world setting, e.g., the ImageNet dataset. However, this setting is not a good proxy for the real-world scenario. This imbalanced data distribution in the training set may largely degrade the performance of the machine learning or deep learning-based method.\n",
        "\n",
        "Our goal is to build a CNN model that can accurately classify the images into their respective categories under imbalanced settings.\n",
        "\n",
        "### Readings before you start\n",
        "\n",
        "1. Bag of tricks for long-tailed visual recognition with deep convolutional neural networks [[Paper]](http://www.lamda.nju.edu.cn/zhangys/papers/AAAI_tricks.pdf) [[Github]](https://github.com/zhangyongshun/BagofTricks-LT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7ZLzUC5gygR"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import csv\n",
        "import math\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(palette='pastel')\n",
        "\n",
        "np.random.seed(568)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6ut6w0vFjzJ"
      },
      "source": [
        "## Prepare Imbalanced CIFAR-30 Dataset from CIFAR-*100*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyUSBHY4o44d"
      },
      "source": [
        "You will be building the imbalanced version of CIFAR-30 from the CIFAR-100:\n",
        "\n",
        "\\begin{equation*}\n",
        "    \\beta = \\frac{max(\\{n_1, n_2, \\cdots, n_k\\})}{min(\\{n_1, n_2, \\cdots, n_k\\})}\\\n",
        "\\end{equation*}\n",
        "\n",
        "\\noindent where $n_i$ represents the number of images for class $i$. Therefore, the larger the imbalance factor $\\beta$ is, the harder it gets for doing long-tailed recognition on such data. With a $\\beta=100$ version of CIFAR-100, the head classes will have $500$ training samples while the tail classes only have $5$ training samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBhyWtJIhckb"
      },
      "outputs": [],
      "source": [
        "# create a custom dataset CIFAR30 from CIFAR100\n",
        "class CIFAR30(torchvision.datasets.CIFAR100):\n",
        "    # cifar100 has 100 classes, we only want 30\n",
        "    cls_num = 30\n",
        "\n",
        "    def __init__(self, root, imb_type='exp', imb_factor=0.01, rand_number=0, train=True,\n",
        "                 transform=None, target_transform=None,\n",
        "                 download=False, imbalanced=False):\n",
        "        super(CIFAR30, self).__init__(root, train, transform, target_transform, download)\n",
        "        np.random.seed(rand_number)\n",
        "\n",
        "        self.remove_extra_class(self.cls_num)\n",
        "\n",
        "        if self.train and imbalanced:\n",
        "            img_num_list = self.get_img_num_per_cls(self.cls_num, imb_type, imb_factor)\n",
        "            self.gen_imbalanced_data(img_num_list)\n",
        "\n",
        "        self.update_num_per_cls()\n",
        "\n",
        "    # remove extra classes to make it 30 classes\n",
        "    def remove_extra_class(self, cls_num):\n",
        "        new_data = []\n",
        "        new_targets = []\n",
        "        targets_np = np.array(self.targets, dtype=np.int64)\n",
        "        classes = np.unique(targets_np)\n",
        "        for i in range(cls_num):\n",
        "            idx = np.where(targets_np == i)[0]\n",
        "            new_data.append(self.data[idx, ...])\n",
        "            new_targets.extend([i, ] * len(idx))\n",
        "        new_data = np.vstack(new_data)\n",
        "        self.data = new_data\n",
        "        self.targets = new_targets\n",
        "\n",
        "\n",
        "    # get the number of images per class we desire\n",
        "    def get_img_num_per_cls(self, cls_num, imb_type, imb_factor):\n",
        "        img_max = len(self.data) / cls_num\n",
        "        img_num_per_cls = []\n",
        "        if imb_type == 'exp':\n",
        "            for cls_idx in range(cls_num):\n",
        "                num = img_max * (imb_factor ** (cls_idx / (cls_num - 1.0)))\n",
        "                img_num_per_cls.append(int(num))\n",
        "        elif imb_type == 'step':\n",
        "            for cls_idx in range(cls_num // 2):\n",
        "                img_num_per_cls.append(int(img_max))\n",
        "            for cls_idx in range(cls_num // 2):\n",
        "                img_num_per_cls.append(int(img_max * imb_factor))\n",
        "        else:\n",
        "            img_num_per_cls.extend([int(img_max)] * cls_num)\n",
        "        return img_num_per_cls\n",
        "\n",
        "    # generate imbalanced data from original dataset with given img_num_per_cls\n",
        "    def gen_imbalanced_data(self, img_num_per_cls):\n",
        "        new_data = []\n",
        "        new_targets = []\n",
        "        targets_np = np.array(self.targets)\n",
        "        classes = np.unique(targets_np)\n",
        "        self.num_per_cls_dict = dict()\n",
        "        for the_class, the_img_num in zip(classes, img_num_per_cls):\n",
        "            self.num_per_cls_dict[the_class] = the_img_num\n",
        "            idx = np.where(targets_np == the_class)[0]\n",
        "            np.random.shuffle(idx)\n",
        "            selec_idx = idx[:the_img_num]\n",
        "            new_data.append(self.data[selec_idx, ...])\n",
        "            new_targets.extend([the_class, ] * the_img_num)\n",
        "        new_data = np.vstack(new_data)\n",
        "        self.data = new_data\n",
        "        self.targets = new_targets\n",
        "\n",
        "    def get_cls_num_list(self):\n",
        "        cls_num_list = []\n",
        "        for i in range(self.cls_num):\n",
        "            cls_num_list.append(self.num_per_cls_dict[i])\n",
        "        return cls_num_list\n",
        "\n",
        "    def update_num_per_cls(self):\n",
        "        targets_np = np.array(self.targets, dtype=np.int64)\n",
        "        classes = np.unique(targets_np)\n",
        "        self.num_per_cls_dict = dict()\n",
        "        for cls in classes:\n",
        "            self.num_per_cls_dict[cls] = len(np.where(targets_np == cls)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8T3kHUupODe"
      },
      "source": [
        "We will also be adapting some extra transorms (augmentations) on our CIFAR-30:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPa2_H90imQT"
      },
      "outputs": [],
      "source": [
        "# transforms for training and testing\n",
        "training_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.RandomHorizontalFlip(p=1),\n",
        "     transforms.RandomAffine(degrees=60),\n",
        "     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "testing_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "# create the datasets\n",
        "cifar30_trainset = CIFAR30(root='./data', train=True, download=True,\n",
        "                                transform=training_transform, imbalanced=False)\n",
        "im_cifar30_trainset = CIFAR30(root='./data', train=True, download=True,\n",
        "                                transform=training_transform, imbalanced=True)\n",
        "cifar30_testset = CIFAR30(root='./data', train=False, download=True,\n",
        "                               transform=testing_transform, imbalanced=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CQVqL40pXzi"
      },
      "source": [
        "Compare the data (label) distribution of the three dataset `cifar30_trainset`, `im_cifar30_trainset`, and `cifar30_testset` we constructed:\n",
        "\n",
        "1. Balanced Training Data\n",
        "2. Imbalanced Training Data\n",
        "3. Balanced Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYTuMtTfrfUg"
      },
      "outputs": [],
      "source": [
        "training_distribution = list(cifar30_trainset.num_per_cls_dict.values())\n",
        "im_training_distribution = list(im_cifar30_trainset.num_per_cls_dict.values())\n",
        "testing_distribution = list(cifar30_testset.num_per_cls_dict.values())\n",
        "training_cls = list(im_cifar30_trainset.num_per_cls_dict.keys())\n",
        "\n",
        "plt.subplots(1, 3, sharey=True, figsize=(14,4))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.bar(training_cls, training_distribution, color='blue')\n",
        "plt.title('Training Data (Balanced)')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.bar(training_cls, im_training_distribution, color='blue')\n",
        "plt.title('Training Data (Imbalanced)')\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.bar(training_cls, testing_distribution, color='red')\n",
        "plt.title('Testing Data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZljJaEcJGsA_"
      },
      "source": [
        "Show some images with labels (class names) from dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouwOe97XHli1"
      },
      "outputs": [],
      "source": [
        "def cifar_imshow(img):\n",
        "  img = img / 2 + 0.5 # unnormalize the image\n",
        "  npimg = img.numpy()\n",
        "  return np.transpose(npimg, (1, 2, 0)) # reorganize the channel\n",
        "\n",
        "# visualize some samples in the CIFAR-30 dataset\n",
        "fig, axs = plt.subplots(3, 10, figsize = (12, 4))\n",
        "\n",
        "# loop through subplots and images\n",
        "for i, ax in enumerate(axs.flat):\n",
        "  ax.imshow(cifar_imshow(cifar30_testset[i*100][0]))\n",
        "  ax.axis('off')\n",
        "  ax.set_title('{}'.format(cifar30_testset[i*100][1]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ej_TdcW2Hw8f"
      },
      "source": [
        "## 2-a. Train CNN Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsvho4Av9hpj"
      },
      "source": [
        "Check whether your runtime is on GPU or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xbye-AZu3Ju3"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using device:', device)\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLiYv74275W2"
      },
      "source": [
        "The CNN we will be using in this problem is called ResNet:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-lIhC5u8CFq"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=30):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "my_cnn = ResNet(BasicBlock, [2, 2, 2, 2]).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncDpYjWvsLEj"
      },
      "source": [
        "## Trainer and Tester code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h12Cf5yVy9WM"
      },
      "outputs": [],
      "source": [
        "def trainer(train_loader, valid_loader, model, config, device, weight=None):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduction='mean', weight=weight)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.7)\n",
        "\n",
        "    if not os.path.isdir('./models'):\n",
        "        os.mkdir('./models') # Create directory of saving models.\n",
        "\n",
        "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # Set your model to train mode.\n",
        "        loss_record = []\n",
        "\n",
        "        # tqdm is a package to visualize your training progress.\n",
        "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
        "\n",
        "        for x, y in train_pbar:\n",
        "            optimizer.zero_grad()               # Set gradient to zero.\n",
        "            x, y = x.to(device), y.to(device)   # Move your data to device.\n",
        "            pred = model(x)\n",
        "            loss = criterion(pred, y)\n",
        "            loss.backward()                     # Compute gradient(backpropagation).\n",
        "            optimizer.step()                    # Update parameters.\n",
        "            step += 1\n",
        "            loss_record.append(loss.detach().item())\n",
        "\n",
        "            # Display current epoch number and loss on tqdm progress bar.\n",
        "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
        "            train_pbar.set_postfix({'loss': loss.detach().item()})\n",
        "\n",
        "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
        "        # writer.add_scalar('Loss/train', mean_train_loss, step)\n",
        "\n",
        "        model.eval() # Set your model to evaluation mode.\n",
        "        loss_record = []\n",
        "        val_accuracy = []\n",
        "        for x, y in valid_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                loss = criterion(pred, y)\n",
        "\n",
        "                _, predicted = torch.max(pred.data, 1)\n",
        "                val_accuracy.append((predicted == y).sum().item() / predicted.size(0))\n",
        "            loss_record.append(loss.item())\n",
        "        print('Accuracy:', sum(val_accuracy)/len(val_accuracy))\n",
        "\n",
        "    torch.save(model.state_dict(), config['save_path'])\n",
        "\n",
        "def tester(test_loader, model, config, device):\n",
        "\n",
        "    model.eval() # Set your model to evaluation mode.\n",
        "    loss_record = []\n",
        "    test_accuracy = []\n",
        "    for x, y in test_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            pred = model(x)\n",
        "            _, predicted = torch.max(pred.data, 1)\n",
        "            test_accuracy.append((predicted == y).sum().item() / predicted.size(0))\n",
        "    print(sum(test_accuracy)/len(test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_uDuukPsPvt"
      },
      "source": [
        "## Sample Config Dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySxMJ_YZzH3p"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'seed': 1968990,      # Your seed number, you can pick your lucky number. :)\n",
        "    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n",
        "    'n_epochs': 50,      # Number of epochs.\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.01,\n",
        "    'early_stop': 20,    # If model has not improved for this many consecutive epochs, stop training.\n",
        "    'save_path': './models/baseline_model.ckpt'  # Your model will be saved here.\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OC5pjn49zwi"
      },
      "source": [
        "## Prepare the Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5fS9T97zMwM"
      },
      "outputs": [],
      "source": [
        "# Original CIFAR-30\n",
        "cifar30_train_data, cifar30_valid_data = random_split(cifar30_trainset, [0.8, 0.2])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar30_train_data, batch_size=config['batch_size'], shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(cifar30_valid_data, batch_size=config['batch_size'], shuffle=True)\n",
        "\n",
        "# Imbalanced CIFAR-30\n",
        "im_cifar30_train_data, im_cifar30_valid_data = random_split(im_cifar30_trainset, [0.8, 0.2])\n",
        "\n",
        "im_train_loader = torch.utils.data.DataLoader(im_cifar30_train_data, batch_size=config['batch_size'], shuffle=True)\n",
        "im_valid_loader = torch.utils.data.DataLoader(im_cifar30_valid_data, batch_size=config['batch_size'], shuffle=True)\n",
        "\n",
        "# CIFAR-30 Testing (always balanced)\n",
        "test_loader = torch.utils.data.DataLoader(cifar30_testset, batch_size=config['batch_size'], shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4jLVgZvmnXP"
      },
      "source": [
        "### Train on original CIFAR-30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohHGvWKazaFQ",
        "outputId": "302c24c3-affc-44f0-c767-d4f860185e2e"
      },
      "outputs": [],
      "source": [
        "trainer(im_train_loader,  im_valid_loader, my_cnn, config, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkdbjDhpnagR",
        "outputId": "2c66e95f-6c61-4c93-ce35-66df6ab5767e"
      },
      "outputs": [],
      "source": [
        "tester(test_loader, my_cnn, config, device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JW-pLNGJL7sD"
      },
      "source": [
        "## 2-b. Implement Re-Weighting\n",
        "\n",
        "Hint:\n",
        "\n",
        "Notice there is a \"weight\" argument for the loss we use:\n",
        "\n",
        "```\n",
        "criterion = nn.CrossEntropyLoss(reduction='mean', weight=weight)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "II7p6_aPNNDt"
      },
      "outputs": [],
      "source": [
        "# Please do not modify the config\n",
        "re_weighting_config = {\n",
        "    'seed': 1968990,      # Your seed number, you can pick your lucky number. :)\n",
        "    'select_all': True,   # Whether to use all features.\n",
        "    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n",
        "    'n_epochs': 50,      # Number of epochs.\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.001,\n",
        "    'early_stop': 20,    # If model has not improved for this many consecutive epochs, stop training.\n",
        "    'save_path': './models/re_weighting_model.ckpt'  # Your model will be saved here.\n",
        "}\n",
        "\n",
        "# TODO\n",
        "\n",
        "# ENDS HERE"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "upeewP_G7nC6"
      },
      "source": [
        "## 2-c. Evaluate Re-Weighting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P17NdJNC7mkh"
      },
      "outputs": [],
      "source": [
        "tester(test_loader, my_cnn_re_weighting, re_weighting_config, device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gdA5rvk_IGs-"
      },
      "source": [
        "## 2-d. Implement Re-Sampling\n",
        "\n",
        "Hint:\n",
        "\n",
        "Check out how sampler works in PyTorch's DataLoader!\n",
        "\n",
        "\n",
        "```\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(class_counts) * 500)\n",
        "rs_train_loader = DataLoader(im_cifar30_trainset, batch_size=config['batch_size'], sampler=sampler)\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxE5tl3f8ywK"
      },
      "outputs": [],
      "source": [
        "# Please do not modify the config\n",
        "config = {\n",
        "    'seed': 1968990,      # Your seed number, you can pick your lucky number. :)\n",
        "    'select_all': True,   # Whether to use all features.\n",
        "    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n",
        "    'n_epochs': 50,      # Number of epochs.\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.001,\n",
        "    'early_stop': 20,    # If model has not improved for this many consecutive epochs, stop training.\n",
        "    'save_path': './models/re_sampling_model.ckpt'  # Your model will be saved here.\n",
        "}\n",
        "\n",
        "\n",
        "# TODO\n",
        "\n",
        "# ENDS HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znHJicelsa43"
      },
      "outputs": [],
      "source": [
        "my_cnn_re_sampling = ResNet(BasicBlock, [2, 2, 2, 2]).to(device)\n",
        "trainer(rs_train_loader, test_loader, my_cnn_rs, config, device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RTzf_ucS7xks"
      },
      "source": [
        "## 2-e. Evaluate Re-Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ytyMooRZtjj"
      },
      "outputs": [],
      "source": [
        "tester(test_loader, my_cnn_re_sampling, re_sampling_config, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
